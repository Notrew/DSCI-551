Q2
churn=spark.read.csv("churn.csv",header=True)
import pyspark.sql.functions as fc

a)
>>> churn.filter("gender == 'Male' and churn == 'Yes'").count()
930 

b)
>>> churn = churn.withColumn('TotalCharges', fc.col('TotalCharges').cast('double'))
>>>churn.filter("churn=='Yes'").groupby("gender").agg(fc.max("TotalCharges").alias("max_charge")).show()
+------+----------+                                                             
|gender|max_charge|
+------+----------+
|Female|    8127.6|
|  Male|    8684.8|
+------+----------+

c)
>>> churn.filter("churn=='Yes'").groupby("gender").count().show()
+------+-----+
|gender|count|
+------+-----+
|Female|  939|
|  Male|  930|
+------+-----+

d)
>>> churn.groupby(["churn","contract"]).agg(fc.count("*").alias("cnt")).orderBy(["churn","cnt"],ascending=[True,False]).show()
+-----+--------------+----+
|churn|      contract| cnt|
+-----+--------------+----+
|   No|Month-to-month|2220|
|   No|      Two year|1647|
|   No|      One year|1307|
|  Yes|Month-to-month|1655|
|  Yes|      One year| 166|
|  Yes|      Two year|  48|
+-----+--------------+----+

e)
>>> churn.groupby(["gender","churn"]).count().filter("count(*)>1000").show()
+------+-----+-----+
|gender|churn|count|
+------+-----+-----+
|  Male|   No| 2625|
|Female|   No| 2549|
+------+-----+-----+




